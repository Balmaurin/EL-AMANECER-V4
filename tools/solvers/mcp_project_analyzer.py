#!/usr/bin/env python3
"""
MCP PROJECT ANALYZER & MEMORY TRAINER
====================================

Analiza todo el proyecto SHEILY, extrae capacidades y conocimientos,
y crea sistema de memoria vectoriada con embeddings FAISS.

Capacidades analÃ­ticas:
- Procesamiento completo del proyecto MCP-Phoenix
- ExtracciÃ³n automÃ¡tica de conocimientos ejecutables
- GeneraciÃ³n de embeddings FAISS del corpus completo
- Sistema de memoria entrenada del MCP
- Base de conocimientos vectorizada consultable

Entrena el MCP para ser expert en su propio sistema.
"""

import asyncio
import hashlib
import json
import logging
import os
import sys
import time
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import numpy as np

# Configurar logging avanzado
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('mcp_analyzer.log', encoding='utf-8'),
        logging.StreamHandler(open('mcp_analyzer_console.log', 'w', encoding='utf-8'))
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class ProjectAnalysisResult:
    """Resultado del anÃ¡lisis completo del proyecto"""

    project_version: str = "SHEILY MCP ENTERPRISE v1.0"
    total_files: int = 0
    total_lines: int = 0
    analyzed_modules: List[str] = field(default_factory=list)
    extracted_capabilities: Dict[str, List[str]] = field(default_factory=dict)
    system_architecture: Dict[str, Any] = field(default_factory=dict)
    functional_components: Dict[str, List[str]] = field(default_factory=dict)
    corpus_documents: List[Dict[str, Any]] = field(default_factory=list)
    embeddings_generated: int = 0
    training_datasets: List[Dict[str, Any]] = field(default_factory=list)

@dataclass
class MCPSelfKnowledgeVector:
    """Vector de conocimiento propio del MCP"""

    knowledge_id: str
    content: str
    category: str  # 'capabilities', 'architecture', 'functionality', 'limitations'
    confidence_score: float
    embedding: Optional[np.ndarray] = None
    metadata: Dict[str, Any] = field(default_factory=dict)
    created_at: datetime = field(default_factory=datetime.now)


class MCPProjectAnalyzer:
    """
    Analiza completo el proyecto SHEILY para capacitaciÃ³n MCP
    """

    def __init__(self, project_root: str = None):
        if project_root is None:
            project_root = Path(__file__).parent.parent  # Back to project root

        self.project_root = Path(project_root)
        self.corpus_dir = self.project_root / "universal" / "mcp_corpus"
        self.embeddings_dir = self.project_root / "universal" / "mcp_embeddings"
        self.training_data_dir = self.project_root / "universal" / "mcp_training"

        # Crear directorios
        for dir_path in [self.corpus_dir, self.embeddings_dir, self.training_data_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)

        self.analysis_result = ProjectAnalysisResult()
        self.self_knowledge_vectors: List[MCPSelfKnowledgeVector] = []

        # ConfiguraciÃ³n de FAISS
        self.embedding_dimension = 384  # Para sentence-transformers
        self.faiss_index = None
        self.vector_id_map: Dict[int, str] = {}  # Maps FAISS indices to knowledge IDs
        self.id_vector_map: Dict[str, int] = {}  # Maps knowledge IDs to FAISS indices

        logger.info("ğŸ§  MCP Project Analyzer inicializado")

    async def analyze_entire_project(self) -> ProjectAnalysisResult:
        """
        AnÃ¡lisis completo del proyecto SHEILY para capacitaciÃ³n MCP
        """

        print("=" * 80)
        print("ğŸ§  MCP PROJECT ANALYSIS - ESTUDIO COMPLETO")
        print("=" * 80)

        start_time = time.time()

        try:
            # FASE 1: AnÃ¡lisis estructural del proyecto
            print("\nğŸ“Š FASE 1: AnÃ¡lisis Estructural del Proyecto...")
            await self._analyze_project_structure()

            # FASE 2: ExtracciÃ³n de capacidades del sistema
            print("\nğŸ” FASE 2: ExtracciÃ³n de Capacidades del Sistema...")
            await self._extract_system_capabilities()

            # FASE 3: AnÃ¡lisis de la arquitectura funcional
            print("\nğŸ—ï¸  FASE 3: AnÃ¡lisis de Arquitectura Funcional...")
            await self._analyze_functional_architecture()

            # FASE 4: Procesamiento del cÃ³digo fuente
            print("\nğŸ’» FASE 4: Procesamiento de CÃ³digo Fuente...")
            await self._process_source_code()

            # FASE 5: GeneraciÃ³n del corpus de conocimientos
            print("\nğŸ“š FASE 5: GeneraciÃ³n del Corpus de Conocimientos...")
            await self._generate_knowledge_corpus()

            # FASE 6: CreaciÃ³n de embeddings FAISS
            print("\nğŸ§® FASE 6: CreaciÃ³n de Embeddings FAISS...")
            await self._create_faiss_embeddings()

            # FASE 7: PreparaciÃ³n de datos de entrenamiento del MCP
            print("\nğŸ“ FASE 7: PreparaciÃ³n de Datos de Entrenamiento...")
            await self._prepare_training_data()

            # FASE 8: FinalizaciÃ³n y mÃ©tricas
