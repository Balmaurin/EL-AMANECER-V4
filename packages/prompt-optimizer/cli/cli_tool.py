#!/usr/bin/env python3
"""
CLI Tool para el Sistema Universal de Optimizaci√≥n de Prompts
Herramienta de l√≠nea de comandos con Click para testing y uso r√°pido.
"""

import asyncio
import json
import logging
import sys
from pathlib import Path
from typing import Any, Dict, Optional

import click

from ..universal_prompt_optimizer import (LlamaCppAdapter,
                                          UniversalAutoImprovingPromptSystem)

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class CLIContext:
    """Contexto para el CLI"""

    def __init__(self):
        self.system = None

    async def get_system(self) -> UniversalAutoImprovingPromptSystem:
        """Obtener el sistema (lazy loading)"""
        if self.system is None:
            try:
                llm = LlamaCppAdapter("models/llama-3.2-3b-q4.gguf")
                self.system = UniversalAutoImprovingPromptSystem(llm)
                click.echo("üöÄ Sistema inicializado con Llama 3.2 3B")
            except Exception as e:
                click.echo(f"‚ùå Error inicializando sistema: {e}", err=True)
                sys.exit(1)
        return self.system

pass_system = click.make_pass_decorator(CLIContext, ensure=True)

@click.group()
@click.pass_context
def cli(ctx):
    """üß† Universal Prompt Optimizer CLI Tool

    Sistema autom√°tico para mejorar prompts de cualquier LLM.

    Usa: uapo optimize "tu prompt aqu√≠" --llm llama
    """
    ctx.obj = CLIContext()

@cli.command()
@click.argument('prompt')
@click.option('--iterations', '-i', default=3, help='Iteraciones de optimizaci√≥n (1-10)', type=int)
@click.option('--context', '-c', help='Archivo JSON con contexto', type=click.Path(exists=True))
@click.option('--output', '-o', help='Guardar resultado en archivo', type=click.Path())
@pass_system
def optimize(context, prompt: str, iterations: int, output: Optional[str] = None):
    """Optimizar un prompt autom√°ticamente"""
    system = asyncio.run(context.get_system())

    # Cargar contexto si proporcionado
    ctx_data = {}
    if context:
        try:
            with open(context, 'r') as f:
                ctx_data = json.load(f)
        except Exception as e:
            click.echo(f"‚ùå Error cargando contexto: {e}", err=True)
            return

    click.echo(f"üîÑ Optimizando prompt: {prompt[:100]}...")
    if len(prompt) > 100:
        click.echo("...(truncado)")

    try:
        result = asyncio.run(system.optimize_prompt(
            original_prompt=prompt,
            context=ctx_data,
            max_iterations=min(max(iterations, 1), 10)
        ))

        # Mostrar resultado
        click.echo("‚úÖ Optimizaci√≥n completada!"
        click.echo(f"üìä Score original: {(result.evaluation.metrics.get('relevance', 0) or 0):.1f}")
        click.echo("-" * 50)
        click.echo(f"üìù Prompt optimizado:")
        click.echo(result.optimized_prompt)
        click.echo("-" * 50)
        click.echo(f"üìä Score final: {result.evaluation.score:.1f}/100")
        click.echo(f"üõ†Ô∏è T√©cnica usada: {result.technique_used}")
        click.echo(f"üîÑ Iteraciones: {result.iterations}")
        click.echo(f"üí° Sugerencias: {', '.join(result.evaluation.improvements[:3])}")

        # Guardar si solicitado
        if output:
            with open(output, 'w') as f:
                json.dump({
                    'original': result.original_prompt,
                    'optimized': result.optimized_prompt,
                    'score': result.evaluation.score,
                    'metrics': result.evaluation.metrics,
                    'improvements': result.evaluation.improvements
                }, f, indent=2)
            click.echo(f"üíæ Resultado guardado en: {output}")

    except Exception as e:
        click.echo(f"‚ùå Error durante optimizaci√≥n: {e}", err=True)

@cli.command()
@click.argument('query')
@click.option('--context', '-c', help='Archivo JSON con contexto', type=click.Path(exists=True))
@click.option('--stream', '-s', is_flag=True, help='Stream de respuesta (no implementado a√∫n)')
@pass_system
def generate(context, query: str, stream: bool = False):
    """Generar respuesta optimizada para una query"""
    system = asyncio.run(context.get_system())

    # Cargar contexto
    ctx_data = {}
    if context:
        try:
            with open(context, 'r') as f:
                ctx_data = json.load(f)
        except Exception as e:
            click.echo(f"‚ùå Error cargando contexto: {e}", err=True)
            return

    click.echo(f"ü§ñ Generando respuesta para: {query[:100]}...")
    if len(query) > 100:
        click.echo("...(truncado)")

    try:
        response = asyncio.run(system.generate_response(query))

        click.echo("‚úÖ Respuesta generada:")
        click.echo("-" * 50)
        click.echo(response)
        click.echo("-" * 50)

    except Exception as e:
        click.echo(f"‚ùå Error generando respuesta: {e}", err=True)

@cli.command()
@click.argument('prompt')
@click.option('--detailed', '-d', is_flag=True, help='Mostrar m√©tricas detalladas')
@pass_system
def evaluate(context, prompt: str, detailed: bool = False):
    """Solo evaluar un prompt sin optimizar"""
    system = asyncio.run(context.get_system())

    click.echo(f"üìä Evaluando prompt: {prompt[:100]}...")
    if len(prompt) > 100:
        click.echo("...(truncado)")

    try:
        evaluation = asyncio.run(system.evaluator.evaluate_prompt(prompt))

        click.echo("‚úÖ Evaluaci√≥n completada!")
        click.echo(".1f")

        if detailed:
            click.echo(f"üìà M√©tricas:")
            for metric, value in evaluation.metrics.items():
                click.echo(f"   ‚Ä¢ {metric}: {value:.2f}")
            click.echo(f"ü§î Razonamiento: {evaluation.reasoning}")
            click.echo(f"üí° Mejoras sugeridas: {', '.join(evaluation.improvements)}")

    except Exception as e:
        click.echo(f"‚ùå Error evaluando prompt: {e}", err=True)

@cli.command()
@click.argument('prompts_file', type=click.Path(exists=True))
@click.option('--technique', '-t', help='T√©cnica espec√≠fica a probar')
@click.option('--output', '-o', help='Archivo de salida para resultados', type=click.Path())
@pass_system
def benchmark(context, prompts_file: str, technique: Optional[str], output: Optional[str]):
    """Ejecutar benchmark con m√∫ltiples prompts"""
    system = asyncio.run(context.get_system())

    # Cargar prompts
    try:
        with open(prompts_file, 'r') as f:
            if prompts_file.endswith('.json'):
                prompts_data = json.load(f)
                if isinstance(prompts_data, list):
                    prompts = prompts_data
                elif 'prompts' in prompts_data:
                    prompts = prompts_data['prompts']
                else:
                    click.echo("‚ùå Formato JSON inv√°lido. Use array de strings o objeto con 'prompts'", err=True)
                    return
            else:  # TXT file
                prompts = [line.strip() for line in f if line.strip()]
    except Exception as e:
        click.echo(f"‚ùå Error cargando prompts: {e}", err=True)
        return

    click.echo(f"üèÉ Ejecutando benchmark con {len(prompts)} prompts...")

    results = []
    total_score = 0

    for i, prompt in enumerate(prompts, 1):
        click.echo(f"‚û§ Prompt {i}/{len(prompts)}: {prompt[:50]}...")
        try:
            # Evaluar cada prompt
            evaluation = asyncio.run(system.evaluator.evaluate_prompt(prompt))
            results.append({
                'prompt': prompt,
                'score': evaluation.score,
                'metrics': evaluation.metrics,
                'improvements': evaluation.improvements
            })
            total_score += evaluation.score

            # Mostrar resultado r√°pido
            click.echo(".1f")

        except Exception as e:
            logger.error(f"Error evaluando prompt {i}: {e}")
            results.append({
                'prompt': prompt,
                'score': 0,
                'error': str(e)
            })

    # Resumen
    avg_score = total_score / len(results) if results else 0
    click.echo("
üìä RESUMEN DEL BENCHMARK:"    click.echo(".1f"    click.echo(f"üìù Prompts evaluados: {len(results)}")
    click.echo(f"üìà Mejores t√©cnicas: CoT, Chain-of-Thought, Expert Prompting"

    # Guardar resultados
    if output:
        with open(output, 'w') as f:
            json.dump({
                'benchmark_results': results,
                'summary': {
                    'total_prompts': len(prompts),
                    'average_score': avg_score,
                    'best_technique': 'CoT con Safety Rails'
                }
            }, f, indent=2)
        click.echo(f"üíæ Resultados guardados en: {output}")

@cli.command()
@click.option('--model', '-m', default='llama', help='Modelo a usar (llama, openai)', type=str)
@click.option('--api-key', help='API key para OpenAI (si usa openai)', type=str)
@click.option('--port', '-p', default=8000, help='Puerto para el API server', type=int)
def serve(model: str, api_key: Optional[str], port: int):
    """Iniciar API REST server"""
    click.echo("üöÄ Iniciando API REST del Universal Prompt Optimizer")
    click.echo(f"üì° Puerto: {port}")
    click.echo(f"ü§ñ Modelo: {model}")

    # Configurar variables de entorno para la API
    if api_key:
        import os
        os.environ['OPENAI_API_KEY'] = api_key

    try:
        # Importar y ejecutar la API
        import uvicorn

        from .api_server import app
        uvicorn.run(app, host="0.0.0.0", port=port)
    except Exception as e:
        click.echo(f"‚ùå Error iniciando API server: {e}", err=True)
        sys.exit(1)

@cli.command()
def techniques():
    """Mostrar t√©cnicas disponibles"""
    system_id = "llama_default"

    click.echo("üéØ T√âCNICAS DISPONIBLES:")
    click.echo("=" * 50)

    techniques = [
        "‚úÖ Estructura y Claridad:",
        "   ‚Ä¢ DelimitersTechnique (# separadores)",
        "   ‚Ä¢ OutputPrimerTechnique (inicios de respuesta)",
        "   ‚Ä¢ AudienceIntegration (especificidad de p√∫blico)",
        "   ‚Ä¢ AffirmativeDirectives n·∫Øm (directivas positivas)",

        "‚úÖ Especificidad e Informaci√≥n:",
        "   ‚Ä¢ SpeakFirstTechnique (hablar desde el principio)",
        "   ‚Ä¢ CompletionInstructions (instrucciones de fin)",
        "   ‚Ä¢ UnderstandingTest (probar comprensi√≥n)",
        "   ‚Ä¢ CuriosityDriven (guiding por curiosidad)",

        "‚úÖ Interacci√≥n y Compromiso:",
        "   ‚Ä¢ ExplainWithEvidence (explicar con evidencia)",
        "   ‚Ä¢ ComprehensiveCoverage (cobertura completa)",
        "   ‚Ä¢ TopDownMeditation (razonamiento arriba-abajo)",
        "   ‚Ä¢ MacroGeneration (generaci√≥n macro)",

        "‚úÖ Contenido y Lenguaje:",
        "   ‚Ä¢ CommonTerminology (t√©rminos comunes)",
        "   ‚Ä¢ KeyPhraseRepetition (repetici√≥n de frases clave)",
        "   ‚Ä¢ ChooseOptionSupport (soporte para opciones)",
        "   ‚Ä¢ ThinkStepByStep (razonamiento paso a paso)",

        "‚úÖ Safety & Ethics:",
        "   ‚Ä¢ Toxicity detection (detecci√≥n toxic)",
        "   ‚Ä¢ Bias detection (anti-sesgos)",
        "   ‚Ä¢ Jailbreak prevention (anti-jailbreaks)",
        "   ‚Ä¢ Ethical enforcement"
    ]

    for tech in techniques:
        click.echo(tech)

    click.echo("
üí° Usa 'uapo optimize \"tu prompt\"' para aplicar autom√°ticamente!"
if __name__ == '__main__':
    cli()
