# Sheily AI MCP Enterprise Configuration
LOG_LEVEL=INFO
MAX_WORKERS=4
CACHE_TTL=3600
MEMORY_LIMIT=512
DEBUG_MODE=false

# Webhook integrations (opcional)
SLACK_WEBHOOK=
DISCORD_WEBHOOK=
TEAMS_WEBHOOK=

# Remote Gemini Backend Configuration (Ollama-compatible)
OLLAMA_BASE_URL=https://sheily-ai-backend-749968449333.europe-west1.run.app
LLM_MODEL_NAME=gemma3:1b
SKIP_MODEL_LOAD=true

ENABLE_CONSCIOUSNESS=true
